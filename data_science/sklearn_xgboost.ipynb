{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "First 10 rows of X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "print(\"Feature names:\", feature_names)\n",
    "print(\"Target names:\", target_names)\n",
    "print(\"\\nFirst 10 rows of X:\\n\", X[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Dataset in SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: 150\n",
      "X_train.shape: 105\n",
      "X_test.shape: 45\n",
      "y.shape: 150\n",
      "y_train.shape: 105\n",
      "y_test.shape: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into 70% training data and 30% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size = 0.3, random_state = 1\n",
    ")\n",
    "\n",
    "print(f'X.shape: {X.shape[0]}')\n",
    "print(f'X_train.shape: {X_train.shape[0]}')\n",
    "print(f'X_test.shape: {X_test.shape[0]}')\n",
    "\n",
    "print(f'y.shape: {y.shape[0]}')\n",
    "print(f'y_train.shape: {y_train.shape[0]}')\n",
    "print(f'y_test.shape: {y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model in SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Predictions: ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "classifier_knn.fit(X_train, y_train)\n",
    "y_pred = classifier_knn.predict(X_test)\n",
    "\n",
    "# Finding accuracy by comparing actual response values (y_test) with predicted response value (y_pred)\n",
    "print(f'Accuracy: {metrics.accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# Providing prediction data and the model will make prediction out of that data\n",
    "prediction_data = [[5, 5, 3, 2], [2, 4, 3, 5]]\n",
    "\n",
    "preds = classifier_knn.predict(prediction_data)\n",
    "pred_species = [iris.target_names[p] for p in preds] \n",
    "print(f'Predictions: {pred_species}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['setosa', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Dump/store the model (classifier_knn)\n",
    "joblib.dump(classifier_knn, 'models/iris_classifier_knn.joblib')\n",
    "\n",
    "# Load/call the dumped_model (iris_classifier_knn)\n",
    "loaded_model = joblib.load('models/iris_classifier_knn.joblib')\n",
    "\n",
    "# Use loaded model for another prediction\n",
    "another_prediction_data = [[4, 3.5, 1.3, 1], [4.1, 2.6, 1.4, 0.3]]\n",
    "new_preds = loaded_model.predict(another_prediction_data)\n",
    "new_pred_species = [iris.target_names[p] for p in new_preds] \n",
    "print(f'Predictions: {new_pred_species}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import DMatrix\n",
    "\n",
    "# Dataset loading \n",
    "dataset = loadtxt('../datasets/pima_indians_diabetes.csv', delimiter=',')\n",
    "\n",
    "# Split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# Split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = DMatrix(X_train, label=y_train)\n",
    "dtest = DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build (XGBoost) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <xgboost.core.Booster object at 0x12cf0b530>\n",
      "Predictions: [0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "Accuracy: 72.83%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import train\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss'         # Logarithmic loss metric\n",
    "}\n",
    "num_round = 100  # Number of boosting rounds\n",
    "\n",
    "model = train(params, dtrain, num_round)\n",
    "\n",
    "print(f'Model: {model}')\n",
    "\n",
    "# Make predictions for test data\n",
    "pred = model.predict(dtest)\n",
    "predictions = [round(value) for value in pred]\n",
    "print(f'Predictions: {predictions}')\n",
    "\n",
    "# Evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Project/utopiq/fif/data/training/first_group/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:36:52] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model('models/pima_indians_diabetes_xgboost_binary_logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If Error Happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64bit', '')\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# If you got error message: You are running 32-bit Python on a 64-bit OS\n",
    "\n",
    "# Check where your Python runnning by\n",
    "import platform \n",
    "print(platform.architecture()) \n",
    "\n",
    "# Or\n",
    "import struct \n",
    "print(struct.calcsize(\"P\") * 8)\n",
    "\n",
    "# Solve the problem by execute brew install libomp on your terminal to install libomp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
